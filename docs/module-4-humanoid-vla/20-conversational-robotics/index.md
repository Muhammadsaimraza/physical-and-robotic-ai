# Chapter 20: Conversational Robotics & VLAs

This chapter brings together the power of Large Language Models (LLMs) with robot perception and action. You will learn to build **Vision-Language-Action (VLA)** systems that allow a robot to understand natural language commands and translate them into physical actions.

This is the cutting edge of robotics, where AI's ability to reason about the world through language meets its ability to operate within it. You will learn how to build a complete "Voice-to-Action" pipeline, enabling your robot to respond intelligently to human commands.

## Learning Objectives
By the end of this chapter, you will be able to:

*   Explain the components of a Voice-to-Action pipeline (Speech-to-Text, LLM Planning, Plan-to-Action).
*   Use an LLM for cognitive planning, translating natural language into structured robot plans.
*   Understand the challenges and opportunities of multi-modal interaction in robotics.

## Lessons
*   **Lesson 20.1: The Voice-to-Action Pipeline**
*   **Lesson 20.2: LLM Cognitive Planning**
